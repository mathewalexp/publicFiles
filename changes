// Import necessary libraries
import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.Encoders

// Assuming you have a Java class `Alert` with fields `id` and `name`
// Ensure Spark session is initialized
val spark: SparkSession = SparkSession.builder()
  .appName("Convert DataFrame to Java List")
  .master("local")
  .getOrCreate()

// Sample DataFrame
import spark.implicits._

val df: DataFrame = Seq(
  (1, "Alert1"),
  (2, "Alert2"),
  (3, "Alert3")
).toDF("id", "name")

// Import the Java class (you need to have this class defined and accessible)
import com.yourpackage.Alert

// Define a mapping function
val alertsDS: Dataset[Alert] = df.map(row => {
  val alert = new Alert()
  alert.setId(row.getAs[Int]("id"))  // Use appropriate types
  alert.setName(row.getAs[String]("name"))
  alert
})(Encoders.javaSerialization(classOf[Alert]))

// Convert to List
val alertsList: List[Alert] = alertsDS.collect().toList

// Print the list
alertsList.foreach(alert => println(s"ID: ${alert.getId}, Name: ${alert.getName}"))
